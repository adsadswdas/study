# 限流（服务器）



### [固定窗口计数器算法](#固定窗口计数器算法)

固定窗口其实就是时间窗口，其原理是将时间划分为固定大小的窗口，在每个窗口内限制请求的数量或速率，即固定窗口计数器算法规定了系统单位时间处理的请求数量。

假如我们规定系统中某个接口 1 分钟只能被访问 33 次的话，使用固定窗口计数器算法的实现思路如下：

- 将时间划分固定大小窗口，这里是 1 分钟一个窗口。
- 给定一个变量 `counter` 来记录当前接口处理的请求数量，初始值为 0（代表接口当前 1 分钟内还未处理请求）。
- 1 分钟之内每处理一个请求之后就将 `counter+1` ，当 `counter=33` 之后（也就是说在这 1 分钟内接口已经被访问 33 次的话），后续的请求就会被全部拒绝。
- 等到 1 分钟结束后，将 `counter` 重置 0，重新开始计数。
- ![固定窗口计数器算法](https://static001.infoq.cn/resource/image/8d/15/8ded7a2b90e1482093f92fff555b3615.png)

优点：实现简单，易于理解。

缺点：

- 限流不够平滑。例如，我们限制某个接口每分钟只能访问 30 次，假设前 30 秒就有 30 个请求到达的话，那后续 30 秒将无法处理请求，这是不可取的，用户体验极差！
- 无法保证限流速率，因而无法应对突然激增的流量。例如，我们限制某个接口 1 分钟只能访问 1000 次，该接口的 QPS 为 500，前 55s 这个接口 1 个请求没有接收，后 1s 突然接收了 1000 个请求。然后，在当前场景下，这 1000 个请求在 1s 内是没办法被处理的，系统直接就被瞬时的大量请求给击垮了。



### [滑动窗口计数器算法](#滑动窗口计数器算法)

**滑动窗口计数器算法** 算的上是固定窗口计数器算法的升级版，限流的颗粒度更小。

滑动窗口计数器算法相比于固定窗口计数器算法的优化在于：**它把时间以一定比例分片** 。

例如我们的接口限流每分钟处理 60 个请求，我们可以把 1 分钟分为 60 个窗口。每隔 1 秒移动一次，每个窗口一秒只能处理不大于 `60(请求数)/60（窗口数）` 的请求， 如果当前窗口的请求计数总和超过了限制的数量的话就不再处理其他请求。

很显然， **当滑动窗口的格子划分的越多，滑动窗口的滚动就越平滑，限流的统计就会越精确。**



![滑动窗口计数器算法](https://static001.infoq.cn/resource/image/ae/15/ae4d3cd14efb8dc7046d691c90264715.png)

优点：

- 相比于固定窗口算法，滑动窗口计数器算法可以应对突然激增的流量。
- 相比于固定窗口算法，滑动窗口计数器算法的颗粒度更小，可以提供更精确的限流控制。

缺点：

- 与固定窗口计数器算法类似，滑动窗口计数器算法依然存在限流不够平滑的问题。
- 相比较于固定窗口计数器算法，滑动窗口计数器算法实现和理解起来更复杂一些。

### [漏桶算法](#漏桶算法)

我们可以把发请求的动作比作成注水到桶中，我们处理请求的过程可以比喻为漏桶漏水。我们往桶中以任意速率流入水，以一定速率流出水。当水超过桶流量则丢弃，因为桶容量是不变的，保证了整体的速率。

如果想要实现这个算法的话也很简单，准备一个**队列**用来保存请求，然后我们定期从队列中拿请求来执行就好了（和消息队列削峰/限流的思想是一样的）。

![漏桶算法](https://static001.infoq.cn/resource/image/75/03/75938d1010138ce66e38c6ed0392f103.png)

优点：

- 实现简单，易于理解。
- 可以控制限流速率，避免网络拥塞和系统过载。

缺点：

- 无法应对突然激增的流量，因为只能以固定的速率处理请求，对系统资源利用不够友好。
- 桶流入水（发请求）的速率如果一直大于桶流出水（处理请求）的速率的话，那么桶会一直是满的，一部分新的请求会被丢弃，导致服务质量下降。

实际业务场景中，基本不会使用漏桶算法。

### [令牌桶算法](#令牌桶算法)

令牌桶算法也比较简单。和漏桶算法算法一样，我们的主角还是桶（这限流算法和桶过不去啊）。不过现在桶里装的是令牌了，请求在被处理之前需要拿到一个令牌，请求处理完毕之后将这个令牌丢弃（删除）。我们根据限流大小，按照一定的速率往桶里添加令牌。如果桶装满了，就不能继续往里面继续添加令牌了。

![令牌桶算法](https://static001.infoq.cn/resource/image/ec/93/eca0e5eaa35dac938c673fecf2ec9a93.png)

优点：

- 可以限制平均速率和应对突然激增的流量。
- 可以动态调整生成令牌的速率。

缺点：

- 如果令牌产生速率和桶的容量设置不合理，可能会出现问题比如大量的请求被丢弃、系统过载。
- 相比于其他限流算法，实现和理解起来更复杂一些。







## [针对什么来进行限流？](#针对什么来进行限流)

实际项目中，还需要确定限流对象，也就是针对什么来进行限流。常见的限流对象如下：

- IP ：针对 IP 进行限流，适用面较广，简单粗暴。
- 业务 ID：挑选唯一的业务 ID 以实现更针对性地限流。例如，基于用户 ID 进行限流。
- 个性化：根据用户的属性或行为，进行不同的限流策略。例如， VIP 用户不限流，而普通用户限流。根据系统的运行指标（如 QPS、并发调用数、系统负载等），动态调整限流策略。例如，当系统负载较高的时候，控制每秒通过的请求减少。

针对 IP 进行限流是目前比较常用的一个方案。不过，实际应用中需要注意用户真实 IP 地址的正确获取。常用的真实 IP 获取方法有 X-Forwarded-For 和 TCP Options 字段承载真实源 IP 信息。虽然 X-Forwarded-For 字段可能会被伪造，但因为其实现简单方便，很多项目还是直接用的这种方法。

除了我上面介绍到的限流对象之外，还有一些其他较为复杂的限流对象策略，比如阿里的 Sentinel 还支持 [基于调用关系的限流](https://github.com/alibaba/Sentinel/wiki/流量控制#基于调用关系的流量控制)（包括基于调用方限流、基于调用链入口限流、关联流量限流等）以及更细维度的 [热点参数限流](https://github.com/alibaba/Sentinel/wiki/热点参数限流)（实时的统计热点参数并针对热点参数的资源调用进行流量控制）。

另外，一个项目可以根据具体的业务需求选择多种不同的限流对象搭配使用。





## [单机限流怎么做？](#单机限流怎么做)

单机限流针对的是单体架构应用。

单机限流可以直接使用 Google Guava 自带的限流工具类 `RateLimiter` 。 `RateLimiter` 基于令牌桶算法，可以应对突发流量。

> Guava 地址：https://github.com/google/guava

除了最基本的令牌桶算法(平滑突发限流)实现之外，Guava 的`RateLimiter`还提供了 **平滑预热限流** 的算法实现。

平滑突发限流就是按照指定的速率放令牌到桶里，而平滑预热限流会有一段预热时间，预热时间之内，速率会逐渐提升到配置的速率。



**Bucket4j** 是一个非常不错的基于令牌/漏桶算法的限流库。

> Bucket4j 地址：https://github.com/vladimir-bukhtoyarov/bucket4j

相对于，Guava 的限流工具类来说，Bucket4j 提供的限流功能更加全面。不仅支持单机限流和分布式限流，还可以集成监控，搭配 Prometheus 和 Grafana 使用。

不过，毕竟 Guava 也只是一个功能全面的工具类库，其提供的开箱即用的限流功能在很多单机场景下还是比较实用的。





Spring Cloud Gateway 中自带的单机限流的早期版本就是基于 Bucket4j 实现的。后来，替换成了 **Resilience4j**。

Resilience4j 是一个轻量级的容错组件，其灵感来自于 Hystrix。自[Netflix 宣布不再积极开发 Hystrix](https://github.com/Netflix/Hystrix/commit/a7df971cbaddd8c5e976b3cc5f14013fe6ad00e6) 之后，Spring 官方和 Netflix 都更推荐使用 Resilience4j 来做限流熔断。

> Resilience4j 地址: https://github.com/resilience4j/resilience4j

一般情况下，为了保证系统的高可用，项目的限流和熔断都是要一起做的。

Resilience4j 不仅提供限流，还提供了熔断、负载保护、自动重试等保障系统高可用开箱即用的功能。并且，Resilience4j 的生态也更好，很多网关都使用 Resilience4j 来做限流熔断的。

因此，在绝大部分场景下 Resilience4j 或许会是更好的选择。如果是一些比较简单的限流场景的话，Guava 或者 Bucket4j 也是不错的选择。



## [分布式限流怎么做？](#分布式限流怎么做)

分布式限流针对的分布式/微服务应用架构应用，在这种架构下，单机限流就不适用了，因为会存在多种服务，并且一种服务也可能会被部署多份。

分布式限流常见的方案：

- **借助中间件限流**：可以借助 Sentinel 或者使用 Redis 来自己实现对应的限流逻辑。
- **网关层限流**：比较常用的一种方案，直接在网关层把限流给安排上了。不过，通常网关层限流通常也需要借助到中间件/框架。就比如 Spring Cloud Gateway 的分布式限流实现`RedisRateLimiter`就是基于 Redis+Lua 来实现的，再比如 Spring Cloud Gateway 还可以整合 Sentinel 来做限流。

如果你要基于 Redis 来手动实现限流逻辑的话，建议配合 Lua 脚本来做。

**为什么建议 Redis+Lua 的方式？** 主要有两点原因：

- **减少了网络开销**：我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。
- **原子性**：一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。







# 1.令牌桶中有哪些字段

**RATE** (令牌产生速率):表示每隔 RATE 毫秒生成一个令牌。这个值越小，令牌生成的速度越快，流量限制就越宽松。默认情况下，令牌的生成速度是固定的，通常是一个常数。
**CAPACITY (桶容量)**:表示令牌桶的最大容量。令牌桶最多可以存储多少个令牌当生成的令牌数超过这个容量时，多余的令牌会被丢弃。
**curCapcity(当前桶容量):**表示令牌桶中当前剩余的令牌数量。初始时，桶容量为 CAPACITY。
**用来计算自上次消费令牌以(时间戳):**记录上一次消费令牌的时间，timeStamp来经过的时间。每当消费一个令牌或者桶容量被填充时，时间会更新。







# 2.如何进行限流

**getToken()方法(令牌请求和生成)**
这个方法用于请求获取令牌，控制限流的核心逻辑就是在这里:
**如果桶中有令牌(curCapacity>0)**
直接消耗一个令牌并返回 true ，表示允许请求处理

**如果桶中没有令牌(curcapacity==0)**
通过计算当前时间和上次时间的差值(current-timestamp)，来判断是否已经过了足够的时间(大于等于 RATE )生成新令牌。如果 current-timestamp>= RATE(即足够的时间已过去)，表示该时间间隔内可以生成新的令牌。然后，系统通过以下方式计算可以生成的令牌数:
**current-timeStamp/RATE >=2** 计算的结果是判断在这段时间内产生了多少个令牌，RATE 为每个令牌的生成间隔(单位为毫秒)，每经过RATE 毫秒生成一个令牌。
**根据时间间隔生成的令牌数((current-timeStamp)/RATE-1)**将这些令牌加到 curcapacity中，表示令牌桶中的容量增加了相应数量的令牌。
**限制容量:**如果生成的令牌数量超过了桶的最大容量CAPACITY，会将curca
pacity 限制为最大容量CAPACITY ，保证令牌桶中的令牌不会超过容量。
然后，更新 timestamp 为当前时间，表示上次操作的时间被刷新。
**如果请求的时间间隔不足(current-timeStamp<RATE )，**也就是桶中的令牌数已经用尽，但还没有生成新的令牌时，方法会返回false，表示当前请求被限流，无法处理。







# RateLimitProvider

## 1.本类的作用是什么?

主要功能是提供速率限制(Rate Limiting)相关的服务

## 2.Map 存储的是?

rateLimitMap 是一个 HashMap 类型的成员变量，它用于存储每个接口的速率限制器实例。 Map<String，RateLimit>的键是接口的名称(interfaceName)值是对应的速率限制器实例。
这样设计可以让 RateLimitProvider 在调用时根据不同的接口名称返回相应的速率限制器，确保不同的接口有不同的速率限制策略。

## 3.讲讲 getRateLimit 方法

getRateLimit 方法用于根据接口名称 interfaceName返回相应的速率限制器实例(RateLimit 类型)
如果 rateLimitMap 中已经包含该接口名称的速率限制器实例，直接返回该实例如果没有，则创建一个新的速率限制器实例并存入 rateLimitMap 中。









# 熔断

### 1. 为什么使用AtomicInteger类型？

- `AtomicInteger`能够保证在并发情况下的线程安全性和原子性。

### 2. 为什么要有半开（HALF_OPEN）状态？

- 半开状态用于测试服务是否已经恢复，仅允许部分请求通过，避免一次性大量请求导致服务再次崩溃（雪崩效应）。

### 3. 为什么要记录lastFailureTime？

- 用于判断OPEN状态是否达到了重新试探服务（进入HALF_OPEN）的时间。

### 4. 半开状态下成功率如何计算？是否有可能出现问题？

- 通过`successCount/requestCount`来计算成功率。
- 存在问题：请求数量较少时成功率容易波动，因此需要合理设置请求基数，以避免误判。

### 5.代码中的`synchronized`的作用是什么？

- 保证状态切换时操作的线程安全，防止并发状态更新导致的数据不一致。

### 6.如何改进当前实现的熔断器？

- 添加更多状态指标，如失败率、失败窗口时间（时间窗口内的失败次数）。
- 增强监控报警能力、完善日志和指标统计，帮助诊断问题。

### 7. 为什么每次状态改变时要重置计数器？

- 防止前一个状态的历史数据影响新的状态判断，使每次状态变更后是一个干净的起点。











## 一、熔断器和限流器（如令牌桶、漏桶）的区别是什么？

| 区别维度     | 熔断器（Circuit Breaker）                  | 限流器（Rate Limiter，如令牌桶、漏桶）           |
| ------------ | ------------------------------------------ | ------------------------------------------------ |
| **核心思想** | 服务异常时快速失败，避免级联故障，保护系统 | 限制服务调用频率或请求数量，保护系统免受流量冲击 |
| **场景定位** | 应对服务不稳定或宕机等异常情况             | 应对突发流量或高负载场景                         |
| **实现原理** | 状态机（关闭、打开、半开）                 | 算法控制（令牌桶、漏桶）                         |
| **作用时机** | 服务出现故障之后                           | 服务正常，但请求过多时                           |
| **典型表现** | 服务失败达到阈值，短暂不允许请求           | 请求过快时，拒绝或延迟处理                       |

> **总结：** 熔断器关注服务本身的异常情况，通过快速失败防止连锁反应；限流器关注外部请求流量，防止系统过载。

------

## 二、熔断器在微服务架构中的应用场景有哪些？

熔断器主要适用于微服务中各个服务间调用，典型场景包括：

- **下游服务故障隔离**：
  - 当下游服务出现延迟高、频繁超时或异常情况时，熔断器自动打开，防止故障向上游传播，保障整体系统的稳定。
- **快速失败，避免请求堆积**：
  - 当某个服务响应缓慢或不可用时，熔断器会快速返回错误，避免请求阻塞和资源耗尽。
- **服务恢复探测**：
  - 服务发生故障后，熔断器短暂打开，随后通过少量请求探测服务恢复状态，以便及时恢复流量。
- **防止级联故障（雪崩效应）**：
  - 通过熔断器机制，避免某个服务的故障引发大范围的连锁反应。

------

## 三、你了解哪些熔断框架？

常见且成熟的熔断框架包括：

| 框架                     | 特点                                                         | 使用场景或现状                                               |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Hystrix**（Netflix）   | Java开源框架，支持熔断、降级、线程隔离、超时控制，曾广泛应用于Spring Cloud | 目前已停止维护，仍在一些老项目中使用，但官方推荐迁移至Resilience4j |
| **Resilience4j**         | 轻量级Java熔断框架，功能丰富（熔断、限流、降级、重试等），基于函数式编程风格，性能优秀 | Spring Cloud最新推荐的熔断器解决方案，适合新项目             |
| **Sentinel**（阿里巴巴） | 面向分布式服务的流量控制框架，具备熔断、限流、降级功能，拥有完善的监控平台，生态良好 | 适用于分布式、微服务环境，尤其是Spring Cloud Alibaba体系     |

> **推荐答案：** 我比较熟悉的是`Hystrix`和`Resilience4j`。
>
> - Hystrix曾是最流行的熔断器框架，目前官方已停止维护，业界普遍转向Resilience4j。
> - Resilience4j更加轻量级，提供函数式接口，易用性强，性能好，且整合了熔断、限流、重试、降级等多种策略，是目前微服务领域首选的熔断框架。

------

## 四、实际项目中遇到熔断器的哪些问题，如何排查解决？

实际项目中常见的问题：

### 问题1：熔断阈值设置不合理

- **表现**：熔断器频繁打开，误判服务异常。

- 排查方法

  ：

  - 通过监控查看失败率、请求延迟、熔断器状态等指标。
  - 根据业务流量和服务实际表现，合理调整熔断阈值。

### 问题2：半开状态恢复逻辑不佳

- **表现**：半开状态频繁反复，服务刚恢复又被迅速熔断。

- 排查方法

  ：

  - 检查半开状态下的探测请求量是否足够（避免样本过少）。
  - 调整半开恢复策略（如增加成功次数占比，或适当延长半开持续时间）。

### 问题3：缺乏有效监控和报警

- **表现**：服务熔断时未及时发现，造成业务损失。

- 排查方法

  ：

  - 建立熔断器指标监控，包括熔断状态、失败次数、恢复时间。
  - 接入报警平台，设置阈值告警，确保熔断后第一时间感知。

### 问题4：线程池/信号量隔离不当（针对Hystrix）

- **表现**：线程池耗尽导致服务响应变慢，或熔断异常。

- 排查方法

  ：

  - 优化线程池大小，调整隔离策略，确保资源合理分配。
  - 推荐使用信号量隔离或结合异步调用模型，减少线程资源压力。

### 实际案例（示例）：

在我实际项目中，曾经使用Hystrix时遇到过半开状态反复切换的问题，表现为服务刚刚恢复正常，很快又进入熔断状态。排查后发现，原因是半开状态下探测请求量太少，偶尔几个请求失败导致比例迅速降低至阈值以下。

解决办法：

- 提高半开状态下探测请求基数（比如从原先的5次增加到20次），减少误判。
- 同时适当提高成功比例阈值（如从50%提高到70%），确保服务真正稳定后再恢复流量。



